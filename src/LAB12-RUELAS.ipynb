{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6548b784",
   "metadata": {},
   "source": [
    "# Sesión 12: DISTRIBUCIONES DE PROBABILIDAD A PRIORI Y POSTERIOR\n",
    "Realizado por:\n",
    "\n",
    "**- Ruelas Flores, César Diego**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80464f",
   "metadata": {},
   "source": [
    "## VARIABLES GLOBALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aec5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install polars numpy matplotlib scikit-learn category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4924163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fb3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\ruelas\\lab12\\.venv\\lib\\site-packages (20.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2590727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de librerías necesarias\n",
    "# !pip install polars scikit-learn category-encoders pytest\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "# Semilla global para reproducibilidad\n",
    "SEED = 42\n",
    "\n",
    "# Ruta al archivo de datos\n",
    "DATA_PATH = \"obesidad.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586620a1",
   "metadata": {},
   "source": [
    "## FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dccf7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from category_encoders import OneHotEncoder\n",
    "from typing import Tuple, List\n",
    "\n",
    "def load_data(path: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga el dataset desde un archivo CSV utilizando polars.\n",
    "\n",
    "    Args:\n",
    "        path (str): Ruta al archivo CSV.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame con los datos cargados.\n",
    "    \"\"\"\n",
    "    return pl.read_csv(path)\n",
    "\n",
    "def check_missing_values(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Verifica la presencia de valores faltantes en el DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): DataFrame a verificar.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame con el conteo de valores faltantes por columna.\n",
    "    \"\"\"\n",
    "    return df.null_count()\n",
    "\n",
    "def remove_outliers(df: pl.DataFrame, columns: List[str]) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina outliers utilizando el método del rango intercuartílico (IQR).\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): DataFrame original.\n",
    "        columns (List[str]): Lista de nombres de columnas numéricas.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame sin outliers.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        q1 = df.select(pl.col(col).quantile(0.25)).to_series()[0]\n",
    "        q3 = df.select(pl.col(col).quantile(0.75)).to_series()[0]\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        df = df.filter((pl.col(col) >= lower_bound) & (pl.col(col) <= upper_bound))\n",
    "    return df\n",
    "\n",
    "def encode_categorical(df: pl.DataFrame, categorical_cols: List[str]) -> Tuple[pl.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Codifica variables categóricas utilizando one-hot encoding con Polars.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): DataFrame original.\n",
    "        categorical_cols (List[str]): Columnas categóricas a codificar.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pl.DataFrame, List[str]]: DataFrame codificado y nombres de las columnas resultantes.\n",
    "    \"\"\"\n",
    "    df_cat = df.select(categorical_cols)\n",
    "    df_encoded = df_cat.to_dummies()\n",
    "    df_non_cat = df.drop(categorical_cols)\n",
    "    final_df = df_non_cat.hstack(df_encoded)\n",
    "    return final_df, final_df.columns\n",
    "\n",
    "\n",
    "def split_data(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Divide los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Variables independientes.\n",
    "        y (np.ndarray): Variable objetivo.\n",
    "        test_size (float, optional): Proporción del conjunto de prueba. Default es 0.2.\n",
    "        random_state (int, optional): Semilla para reproducibilidad. Default es 42.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: Conjuntos de entrenamiento y prueba para X e y.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "def train_and_evaluate_model(model, X_train: np.ndarray, X_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de clasificación.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo de clasificación.\n",
    "        X_train (np.ndarray): Características de entrenamiento.\n",
    "        X_test (np.ndarray): Características de prueba.\n",
    "        y_train (np.ndarray): Etiquetas de entrenamiento.\n",
    "        y_test (np.ndarray): Etiquetas de prueba.\n",
    "\n",
    "    Returns:\n",
    "        float: Precisión del modelo en el conjunto de prueba.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b4ca6",
   "metadata": {},
   "source": [
    "## IMPLEMENTACIÓN PRINCIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf02c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Verificando valores faltantes...\n",
      "shape: (1, 17)\n",
      "┌────────┬─────┬────────┬────────┬───┬─────┬──────┬────────┬────────────┐\n",
      "│ Gender ┆ Age ┆ Height ┆ Weight ┆ … ┆ TUE ┆ CALC ┆ MTRANS ┆ NObeyesdad │\n",
      "│ ---    ┆ --- ┆ ---    ┆ ---    ┆   ┆ --- ┆ ---  ┆ ---    ┆ ---        │\n",
      "│ u32    ┆ u32 ┆ u32    ┆ u32    ┆   ┆ u32 ┆ u32  ┆ u32    ┆ u32        │\n",
      "╞════════╪═════╪════════╪════════╪═══╪═════╪══════╪════════╪════════════╡\n",
      "│ 0      ┆ 0   ┆ 0      ┆ 0      ┆ … ┆ 0   ┆ 0    ┆ 0      ┆ 0          │\n",
      "└────────┴─────┴────────┴────────┴───┴─────┴──────┴────────┴────────────┘\n",
      "Eliminando outliers...\n"
     ]
    }
   ],
   "source": [
    "# LAB12-RUELAS.ipynb \n",
    "\n",
    "from utils import load_data, check_missing_values, remove_outliers, encode_categorical, split_data, train_and_evaluate_model\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Parte A: Preprocesamiento de Datos\n",
    "print(\"Cargando datos...\")\n",
    "df = load_data(DATA_PATH)\n",
    "\n",
    "print(\"Verificando valores faltantes...\")\n",
    "missing = check_missing_values(df)\n",
    "print(missing)\n",
    "\n",
    "print(\"Eliminando outliers...\")\n",
    "numerical_cols = ['Age', 'Height', 'Weight']\n",
    "df_clean = remove_outliers(df, numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee3c1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificando variables categóricas...\n"
     ]
    }
   ],
   "source": [
    "# Parte B: Codificación de Variables Categóricas\n",
    "print(\"Codificando variables categóricas...\")\n",
    "categorical_cols = [col for col in df_clean.columns if col not in numerical_cols + ['NObeyesdad']]\n",
    "df_encoded, feature_names = encode_categorical(df_clean, categorical_cols)\n",
    "\n",
    "# Preparar características y etiquetas\n",
    "X = df_encoded.drop(\"NObeyesdad\").to_numpy()\n",
    "y = df_encoded[\"NObeyesdad\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c3af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo datos en entrenamiento y prueba...\n",
      "Entrenando y evaluando GaussianNB...\n",
      "Accuracy: 0.5243\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.51      0.78      0.62        54\n",
      "      Normal_Weight       0.50      0.18      0.26        56\n",
      "     Obesity_Type_I       0.42      0.35      0.38        57\n",
      "    Obesity_Type_II       0.39      0.94      0.55        54\n",
      "   Obesity_Type_III       0.97      0.98      0.98        65\n",
      " Overweight_Level_I       0.38      0.15      0.21        54\n",
      "Overweight_Level_II       0.45      0.20      0.27        51\n",
      "\n",
      "           accuracy                           0.52       391\n",
      "          macro avg       0.52      0.51      0.47       391\n",
      "       weighted avg       0.53      0.52      0.48       391\n",
      "\n",
      "Entrenando y evaluando MultinomialNB...\n",
      "Accuracy: 0.6317\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.77      0.67      0.71        54\n",
      "      Normal_Weight       0.56      0.50      0.53        56\n",
      "     Obesity_Type_I       0.54      0.47      0.50        57\n",
      "    Obesity_Type_II       0.59      0.85      0.70        54\n",
      "   Obesity_Type_III       0.96      1.00      0.98        65\n",
      " Overweight_Level_I       0.55      0.44      0.49        54\n",
      "Overweight_Level_II       0.39      0.41      0.40        51\n",
      "\n",
      "           accuracy                           0.63       391\n",
      "          macro avg       0.62      0.62      0.62       391\n",
      "       weighted avg       0.63      0.63      0.63       391\n",
      "\n",
      "Precisión GaussianNB: 0.5243\n",
      "Precisión MultinomialNB: 0.6317\n"
     ]
    }
   ],
   "source": [
    "# Parte C: División de Datos y Modelado\n",
    "print(\"Dividiendo datos en entrenamiento y prueba...\")\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "print(\"Entrenando y evaluando GaussianNB...\")\n",
    "gnb = GaussianNB()\n",
    "acc_gnb = train_and_evaluate_model(gnb, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Entrenando y evaluando MultinomialNB...\")\n",
    "mnb = MultinomialNB()\n",
    "acc_mnb = train_and_evaluate_model(mnb, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Comparación de modelos\n",
    "print(f\"Precisión GaussianNB: {acc_gnb:.4f}\")\n",
    "print(f\"Precisión MultinomialNB: {acc_mnb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cbf23",
   "metadata": {},
   "source": [
    "## TESTING (..test/test_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../tests/test_utils.py\n",
    "# tests\n",
    "import pytest\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from src.utils import (\n",
    "    load_data,\n",
    "    check_missing_values,\n",
    "    remove_outliers,\n",
    "    encode_categorical,\n",
    "    split_data,\n",
    "    train_and_evaluate_model\n",
    ")\n",
    "\n",
    "def test_load_data(tmp_path):\n",
    "    csv_path = tmp_path / \"test.csv\"\n",
    "    csv_path.write_text(\"a,b\\n1,2\\n3,4\")\n",
    "    df = load_data(str(csv_path))\n",
    "    assert df.shape == (2, 2)\n",
    "    assert df.columns == [\"a\", \"b\"]\n",
    "\n",
    "def test_check_missing_values():\n",
    "    df = pl.DataFrame({\"a\": [1, None, 3], \"b\": [4, 5, None]})\n",
    "    result = check_missing_values(df)\n",
    "\n",
    "    # Convertimos a diccionario para comparar más fácilmente\n",
    "    missing_dict = dict(zip(result.columns, result.row(0)))\n",
    "    \n",
    "    assert missing_dict[\"a\"] == 1\n",
    "    assert missing_dict[\"b\"] == 1\n",
    "\n",
    "\n",
    "def test_remove_outliers():\n",
    "    df = pl.DataFrame({\"a\": [1, 2, 3, 100]})\n",
    "    cleaned = remove_outliers(df, [\"a\"])\n",
    "    assert 100 not in cleaned[\"a\"].to_list()\n",
    "    assert len(cleaned) == 3\n",
    "\n",
    "def test_encode_categorical():\n",
    "    df = pl.DataFrame({\"color\": [\"red\", \"blue\", \"red\"], \"size\": [\"S\", \"M\", \"L\"], \"value\": [10, 20, 30]})\n",
    "    encoded_df, feature_names = encode_categorical(df, [\"color\", \"size\"])\n",
    "    assert \"value\" in feature_names\n",
    "    assert any(\"color_red\" in col or \"color_blue\" in col for col in feature_names)\n",
    "    assert encoded_df.shape[0] == 3\n",
    "\n",
    "def test_split_data():\n",
    "    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "    y = np.array([0, 0, 1, 1])\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.5, random_state=0)\n",
    "    assert len(X_train) == 2\n",
    "    assert len(X_test) == 2\n",
    "    assert sorted(np.concatenate([y_train, y_test])) == [0, 0, 1, 1]\n",
    "\n",
    "def test_train_and_evaluate_model(capsys):\n",
    "    X = np.array([[1, 2], [1, 3], [4, 5], [6, 7]])\n",
    "    y = np.array([0, 0, 1, 1])\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.5, random_state=0)\n",
    "    acc = train_and_evaluate_model(GaussianNB(), X_train, X_test, y_train, y_test)\n",
    "    captured = capsys.readouterr()\n",
    "    assert \"Accuracy:\" in captured.out\n",
    "    assert 0 <= acc <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f2b22",
   "metadata": {},
   "source": [
    "## EJECUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aedf691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15648002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Ruelas\\lab12\\Data_Mining-LAB12\n",
      "Directorio de trabajo actual establecido en: C:\\Ruelas\\lab12\\Data_Mining-LAB12\n",
      "PYTHONPATH establecido en: C:\\Ruelas\\lab12\\Data_Mining-LAB12;\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Ruta raíz de tu proyecto\n",
    "project_root_path = r'C:\\Ruelas\\lab12\\Data_Mining-LAB12'\n",
    "\n",
    "# Cambiar el directorio de trabajo a la raíz del proyecto\n",
    "%cd {project_root_path}\n",
    "print(f\"Directorio de trabajo actual establecido en: {os.getcwd()}\")\n",
    "\n",
    "# Configurar PYTHONPATH para que Python encuentre el paquete 'src'\n",
    "os.environ['PYTHONPATH'] = project_root_path + os.pathsep + os.environ.get('PYTHONPATH', '')\n",
    "print(f\"PYTHONPATH establecido en: {os.environ['PYTHONPATH']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c702d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.0, pytest-8.4.0, pluggy-1.6.0 -- c:\\Ruelas\\lab12\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Ruelas\\lab12\\Data_Mining-LAB12\n",
      "configfile: pytest.ini\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 6 items\n",
      "\n",
      "tests/test_utils.py::test_load_data \u001b[32mPASSED\u001b[0m\u001b[32m                               [ 16%]\u001b[0m\n",
      "tests/test_utils.py::test_check_missing_values \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 33%]\u001b[0m\n",
      "tests/test_utils.py::test_remove_outliers \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 50%]\u001b[0m\n",
      "tests/test_utils.py::test_encode_categorical \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 66%]\u001b[0m\n",
      "tests/test_utils.py::test_split_data \u001b[32mPASSED\u001b[0m\u001b[32m                              [ 83%]\u001b[0m\n",
      "tests/test_utils.py::test_train_and_evaluate_model \u001b[32mPASSED\u001b[0m\u001b[32m                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 1.42s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests/test_utils.py -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
